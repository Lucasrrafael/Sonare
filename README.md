# Sonare
projeto inovatech

## Execu√ß√£o

Execute a aplica√ß√£o principal a partir do diret√≥rio do projeto:

```bash
python -m view.main_screen [--debug] [-c CONF] [-d DISPLAY_SECONDS] [-m MODEL]
```

### Par√¢metros
- `--debug`: ativa o modo debug (desenha as bounding boxes e r√≥tulos no v√≠deo)
- `-c, --conf`: threshold de confian√ßa do YOLO (0.0 a 1.0). Padr√£o: `0.85`
  - Exemplo: `-c 0.7`
- `-d, --display-seconds`: tempo (em segundos) que cada produto permanece na tela. Padr√£o: `6.0`
  - Exemplo: `-d 8`
- `-t, --carousel-time`: dura√ß√£o (em segundos) de cada imagem no carrossel de backgrounds. Padr√£o: `3`
  - Exemplo: `-t 5`
- `-m, --model`: caminho para o modelo de detec√ß√£o (opcional)
  - Se n√£o especificado, o sistema escolhe automaticamente o melhor modelo baseado no hardware

### Suporte a Modelos

A aplica√ß√£o escolhe **automaticamente** o melhor modelo baseado no hardware dispon√≠vel:

#### üöÄ Com GPU NVIDIA
- **TensorRT** (`.engine`) - M√°xima performance em GPU
- **PyTorch CUDA** (`.pt`) - Alternativa se TensorRT n√£o estiver dispon√≠vel
- Caminho padr√£o: `resources/best.engine` ou `resources/best.pt`

#### üíª Sem GPU (CPU Intel)
- **OpenVINO** - Otimizado para CPUs Intel
- Caminho padr√£o: `resources/best_openvino_model`
- **PyTorch CPU** (`.pt`) - Fallback se OpenVINO n√£o estiver dispon√≠vel

#### üéØ Detec√ß√£o Autom√°tica e Transparente

O sistema detecta automaticamente:
- ‚úì Presen√ßa de GPU CUDA
- ‚úì Modelos dispon√≠veis no sistema
- ‚úì Melhor combina√ß√£o hardware/modelo

**Voc√™ n√£o precisa especificar nada** - o sistema escolhe a melhor op√ß√£o automaticamente!

Exemplo de log ao iniciar:
```
GPU CUDA detectada: NVIDIA GeForce RTX 3080
‚úì GPU detectada - usando TensorRT para m√°xima performance
Modelo TensorRT carregado com sucesso: resources/best.engine
```

ou em CPU:
```
GPU n√£o detectada, usando CPU
‚úì CPU detectada - usando OpenVINO para m√°xima performance em CPU
Modelo OpenVINO carregado com sucesso: resources/best_openvino_model
```

#### Monitoramento de Performance

**Todos os modelos** registram o tempo de infer√™ncia detalhado no console em tempo real:

##### Formato de Log
- **OpenVINO**: pr√©-processamento, infer√™ncia, p√≥s-processamento e total
- **TensorRT**: infer√™ncia, p√≥s-processamento e total
- **PyTorch**: infer√™ncia, p√≥s-processamento e total

##### Exemplos de Log
```
[OpenVINO CPU] Infer√™ncia: 25.3ms (pr√©: 3.1ms, p√≥s: 4.2ms, total: 32.6ms) - 2 detec√ß√µes
[TensorRT GPU] Infer√™ncia: 8.5ms (p√≥s: 1.2ms, total: 9.7ms) - 3 detec√ß√µes
[YOLO PyTorch] Infer√™ncia: 42.8ms (p√≥s: 2.5ms, total: 45.3ms) - 2 detec√ß√µes
```

##### Interpreta√ß√£o dos Tempos
- **pr√©**: Convers√£o de formato, redimensionamento, normaliza√ß√£o (apenas OpenVINO)
- **Infer√™ncia**: Tempo puro de execu√ß√£o do modelo neural
- **p√≥s**: Extra√ß√£o e formata√ß√£o das detec√ß√µes
- **total**: Tempo completo do frame (pr√© + infer√™ncia + p√≥s)

### Exemplos

- Executar com detec√ß√£o autom√°tica (recomendado):
```bash
python -m view.main_screen
```

- Executar com debug e confian√ßa 0.6:
```bash
python -m view.main_screen --debug --conf 0.6
```

- Executar com 8 segundos de exibi√ß√£o por produto:
```bash
python -m view.main_screen -d 8
```

- For√ßar uso de modelo PyTorch:
```bash
python -m view.main_screen -m resources/best.pt
```

- For√ßar uso de modelo OpenVINO:
```bash
python -m view.main_screen -m resources/best_openvino_model
```

- For√ßar uso de modelo TensorRT:
```bash
python -m view.main_screen -m resources/best.engine
```

### Testes e Benchmark

#### Testar Modelos
Para testar se os modelos est√£o funcionando corretamente:
```bash
python test_models.py
```

#### Benchmark de Performance
Para comparar o desempenho entre os modelos dispon√≠veis:
```bash
python benchmark_models.py
```

Op√ß√µes do benchmark:
- `-n, --iterations`: N√∫mero de itera√ß√µes (padr√£o: 10)

Exemplo:
```bash
python benchmark_models.py -n 50
```

O script de benchmark mostrar√°:
- Tempo m√©dio, m√≠nimo, m√°ximo e mediano
- Desvio padr√£o
- FPS estimado
- Compara√ß√£o de velocidade entre os modelos

## Fontes TTF para acentua√ß√£o no overlay 

> Precisa de revis√£o

Para exibir acentos nos textos (nome e pre√ßo) sobre o v√≠deo, a aplica√ß√£o procura primeiro por fontes TrueType no caminho local:

```
resources/fonts/DejaVuSans.ttf
resources/fonts/DejaVuSans-Bold.ttf
```

## Requisitos

### Depend√™ncias Python
- Python 3.10+
- Ver todas as depend√™ncias em `requirements.txt`

### Hardware Recomendado

#### Para M√°xima Performance
- **GPU NVIDIA** com suporte CUDA
- TensorRT instalado
- Modelo: `resources/best.engine`

#### Para CPU Intel
- **OpenVINO** instalado
- Modelo: `resources/best_openvino_model`

#### Fallback Universal
- Qualquer CPU/GPU
- PyTorch instalado
- Modelo: `resources/best.pt`

### Instala√ß√£o

1. Instalar depend√™ncias:
```bash
pip install -r requirements.txt
```

2. (Opcional) Para GPU NVIDIA, instalar TensorRT:
```bash
pip install tensorrt
```

3. Preparar modelos:
   - OpenVINO: colocar em `resources/best_openvino_model/`
   - TensorRT: colocar em `resources/best.engine`
   - PyTorch: colocar em `resources/best.pt`

## Performance Esperada

| Hardware | Modelo | FPS Estimado | Lat√™ncia |
|----------|--------|--------------|----------|
| RTX 3080 | TensorRT | ~100 fps | ~10 ms |
| RTX 3060 | TensorRT | ~80 fps | ~12 ms |
| Intel i7 | OpenVINO | ~30-40 fps | ~25-35 ms |
| Intel i5 | OpenVINO | ~20-30 fps | ~35-50 ms |
| CPU Gen√©rica | PyTorch | ~10-20 fps | ~50-100 ms |

**Nota**: Valores aproximados, variam conforme configura√ß√£o espec√≠fica do sistema.
